# Sign_Language_Recognition_using_DeepLearning
Sign_Language_Recognition_using_DeepLearning is a real-time hand gesture recognition system that uses OpenCV for hand tracking and a Convolutional Neural Network (CNN) model built with TensorFlow/Keras for gesture classification. The project is designed to recognize and classify various sign language gestures through a live webcam feed.
Key Features:
  Real-Time Gesture Recognition: Detects hand gestures in real-time using a webcam feed and OpenCVâ€™s hand tracking capabilities.
  CNN-Based Classification: Utilizes a deep learning CNN model to accurately classify gestures such as bathroom, drink, eat, and more.
  Custom Data Collection: Includes scripts to collect custom hand gesture data, enabling the creation of a personalized dataset for training.
  Model Training & Testing: Provides tools to train the model on custom datasets and evaluate its accuracy with visualized metrics during live predictions.
  Accuracy Tracking: Displays real-time accuracy of predictions alongside the live feed.
Technologies:
  Python
  OpenCV
  TensorFlow/Keras
  NumPy
This project is ideal for those interested in gesture-based interfaces, assistive technologies, or sign language recognition systems.
